# ðŸ“Š Monitoreo y MÃ©tricas con Prometheus

## ðŸ“‹ Contenido

1. [Â¿Por quÃ© Monitorear?](#por-quÃ©-monitorear)
2. [Observabilidad: Los Tres Pilares](#observabilidad-los-tres-pilares)
3. [IntroducciÃ³n a Prometheus](#introducciÃ³n-a-prometheus)
4. [Tipos de MÃ©tricas](#tipos-de-mÃ©tricas)
5. [Prometheus FastAPI Instrumentator](#prometheus-fastapi-instrumentator)
6. [MÃ©tricas Personalizadas](#mÃ©tricas-personalizadas)
7. [Dashboards y Alertas](#dashboards-y-alertas)

---

## Â¿Por quÃ© Monitorear?

En producciÃ³n, necesitas responder preguntas como:

- Â¿CuÃ¡ntas requests estÃ¡ recibiendo mi API?
- Â¿CuÃ¡l es el tiempo de respuesta promedio?
- Â¿Hay errores? Â¿CuÃ¡ntos? Â¿De quÃ© tipo?
- Â¿La base de datos estÃ¡ respondiendo lento?
- Â¿Estamos cerca de quedarnos sin memoria?

![Monitoring Stack](../0-assets/04-monitoring-stack.svg)

### Sin Monitoreo vs Con Monitoreo

```
Sin monitoreo:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     "La API estÃ¡              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Usuario â”‚â”€â”€â”€â–¶ lenta" â—€â”€â”€â”€ Queja â—€â”€â”€â”€â”€â”€â”‚ Soporte â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                         â”‚
     â”‚        ???                              â”‚
     â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              "No sÃ© quÃ© pasa,
â”‚   API   â”‚                               voy a revisar logs"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               (30 min despuÃ©s...)

Con monitoreo:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Usuario â”‚                               â”‚  Dashboard  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚ p95: 2.5s âš ï¸â”‚
     â”‚                                    â”‚ errors: 5%  â”‚
     â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â–¼                                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”€â”€â”€â”€â”€â”€metricsâ”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API   â”‚                       â”‚ DB connection pool full â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚ Scaling up...           â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Observabilidad: Los Tres Pilares

![Observability Triad](../0-assets/05-observability-triad.svg)

### 1. Logs (Semana 14 - âœ…)

**Â¿QuÃ© pasÃ³?** - Eventos discretos con contexto.

```json
{"event": "order_created", "order_id": 123, "user_id": 456}
```

### 2. MÃ©tricas (Esta secciÃ³n)

**Â¿CuÃ¡nto?** - Valores numÃ©ricos agregables.

```
http_requests_total{method="GET", path="/api/users"} 1523
http_request_duration_seconds{quantile="0.95"} 0.25
```

### 3. Traces (Avanzado - fuera de scope)

**Â¿DÃ³nde?** - Seguimiento de requests a travÃ©s de servicios.

```
Request â†’ API Gateway â†’ Auth Service â†’ User Service â†’ Database
         [20ms]         [5ms]          [15ms]        [50ms]
```

---

## IntroducciÃ³n a Prometheus

**Prometheus** es el estÃ¡ndar de facto para mÃ©tricas en aplicaciones modernas.

### Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PROMETHEUS                          â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    scrape     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Prometheusâ”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  FastAPI  â”‚                â”‚
â”‚  â”‚  Server   â”‚   /metrics   â”‚   App     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚       â”‚                                                  â”‚
â”‚       â”‚ query                                            â”‚
â”‚       â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚ Grafana  â”‚â—€â”€â”€â”€â”€ Dashboard                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚       â”‚                                                  â”‚
â”‚       â”‚ alert                                            â”‚
â”‚       â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚Alertmanagerâ”‚â”€â”€â”€â”€ Email/Slack                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Modelo Pull vs Push

```
PULL (Prometheus):
Prometheus â”€â”€scrapeâ”€â”€â–¶ App /metrics
           cada 15s

PUSH (otros sistemas):
App â”€â”€pushâ”€â”€â–¶ Metrics Server
    cada request
```

Prometheus usa **pull**: el servidor "raspa" (scrape) las mÃ©tricas de tus aplicaciones periÃ³dicamente.

---

## Tipos de MÃ©tricas

### 1. Counter (Contador)

Valor que **solo incrementa** (o se resetea a 0).

```python
# Ejemplos
http_requests_total = 1523      # Total de requests
errors_total = 45               # Total de errores
orders_created_total = 890      # Ã“rdenes creadas

# Nunca decrementa
# 1523 â†’ 1524 â†’ 1525 âœ…
# 1523 â†’ 1522 âŒ
```

**Uso**: Contar eventos (requests, errores, jobs completados).

### 2. Gauge (Medidor)

Valor que puede **subir o bajar**.

```python
# Ejemplos
active_connections = 45         # Conexiones activas ahora
memory_usage_bytes = 512000000  # Uso de memoria actual
queue_size = 12                 # Items en cola

# Sube y baja
# 45 â†’ 50 â†’ 48 â†’ 52 âœ…
```

**Uso**: Estado actual (conexiones, memoria, temperatura).

### 3. Histogram (Histograma)

DistribuciÃ³n de valores en **buckets** (rangos).

```python
# Tiempo de respuesta en buckets
http_request_duration_seconds_bucket{le="0.1"} = 500   # â‰¤100ms
http_request_duration_seconds_bucket{le="0.5"} = 900   # â‰¤500ms
http_request_duration_seconds_bucket{le="1.0"} = 950   # â‰¤1s
http_request_duration_seconds_bucket{le="+Inf"} = 1000 # todos

# TambiÃ©n incluye:
http_request_duration_seconds_sum = 234.5   # Suma total
http_request_duration_seconds_count = 1000  # NÃºmero de observaciones
```

**Uso**: Latencias, tamaÃ±os de respuesta.

### 4. Summary (Resumen)

Similar a histogram, pero calcula **percentiles** en el cliente.

```python
# Percentiles calculados
http_request_duration_seconds{quantile="0.5"} = 0.05   # p50 (mediana)
http_request_duration_seconds{quantile="0.9"} = 0.12   # p90
http_request_duration_seconds{quantile="0.99"} = 0.45  # p99
```

**Uso**: Cuando necesitas percentiles exactos (pero no agregables entre instancias).

### ComparaciÃ³n

| Tipo | Operaciones | Uso Principal | Agregable |
|------|-------------|---------------|-----------|
| Counter | Incrementar | Eventos totales | âœ… |
| Gauge | Set, Inc, Dec | Estado actual | âœ… |
| Histogram | Observe | Latencias (buckets) | âœ… |
| Summary | Observe | Latencias (percentiles) | âŒ |

---

## Prometheus FastAPI Instrumentator

La forma mÃ¡s fÃ¡cil de aÃ±adir mÃ©tricas a FastAPI.

### InstalaciÃ³n

```bash
uv add prometheus-fastapi-instrumentator
```

### ConfiguraciÃ³n BÃ¡sica

```python
# src/main.py
from fastapi import FastAPI
from prometheus_fastapi_instrumentator import Instrumentator

app = FastAPI()

# Instrumentar la aplicaciÃ³n
Instrumentator().instrument(app).expose(app)

# Esto aÃ±ade automÃ¡ticamente:
# - Endpoint /metrics
# - MÃ©tricas HTTP (requests, latencias, etc.)
```

### MÃ©tricas Incluidas AutomÃ¡ticamente

```
# Contador de requests por mÃ©todo, path y status
http_requests_total{method="GET", handler="/api/users", status="2xx"} 523

# Histograma de duraciÃ³n
http_request_duration_seconds_bucket{method="GET", handler="/api/users", le="0.1"} 400

# TamaÃ±o de requests/responses
http_request_size_bytes_sum 1234567
http_response_size_bytes_sum 9876543

# Requests en progreso
http_requests_in_progress{method="GET", handler="/api/users"} 3
```

### ConfiguraciÃ³n Avanzada

```python
# src/metrics.py
from prometheus_fastapi_instrumentator import Instrumentator, metrics

def setup_metrics(app):
    """Configura mÃ©tricas de Prometheus."""
    
    instrumentator = Instrumentator(
        should_group_status_codes=True,      # 2xx, 3xx, 4xx, 5xx
        should_ignore_untemplated=True,      # Ignorar paths no definidos
        should_respect_env_var=True,         # ENABLE_METRICS env var
        should_instrument_requests_inprogress=True,
        excluded_handlers=["/health", "/metrics"],  # No medir estos
        inprogress_name="http_requests_inprogress",
        inprogress_labels=True,
    )
    
    # AÃ±adir mÃ©tricas adicionales
    instrumentator.add(
        metrics.default(),          # MÃ©tricas por defecto
        metrics.latency(),          # Latencia detallada
        metrics.requests(),         # Contadores de requests
    )
    
    # Instrumentar y exponer
    instrumentator.instrument(app)
    instrumentator.expose(app, include_in_schema=False)  # Ocultar de OpenAPI
    
    return instrumentator
```

---

## MÃ©tricas Personalizadas

### Crear MÃ©tricas de Negocio

```python
# src/metrics.py
from prometheus_client import Counter, Histogram, Gauge

# Contador: Ã³rdenes creadas
orders_created = Counter(
    "orders_created_total",
    "Total de Ã³rdenes creadas",
    ["status", "payment_method"]
)

# Histograma: valor de Ã³rdenes
order_value = Histogram(
    "order_value_dollars",
    "Valor de Ã³rdenes en dÃ³lares",
    buckets=[10, 50, 100, 500, 1000, 5000]
)

# Gauge: usuarios activos
active_users = Gauge(
    "active_users_total",
    "Usuarios activos en este momento"
)

# Gauge: items en cola
queue_size = Gauge(
    "background_queue_size",
    "Items en cola de procesamiento",
    ["queue_name"]
)
```

### Usar las MÃ©tricas

```python
# src/services/order_service.py
from src.metrics import orders_created, order_value

async def create_order(order_data: OrderCreate) -> Order:
    order = await db.create_order(order_data)
    
    # Incrementar contador
    orders_created.labels(
        status="created",
        payment_method=order.payment_method
    ).inc()
    
    # Observar valor
    order_value.observe(order.total)
    
    return order


async def cancel_order(order_id: int) -> None:
    await db.cancel_order(order_id)
    
    orders_created.labels(
        status="cancelled",
        payment_method="n/a"
    ).inc()
```

### MÃ©tricas con Decoradores

```python
from prometheus_client import Counter, Histogram
import functools
import time

request_count = Counter(
    "function_calls_total", 
    "Total function calls",
    ["function"]
)

request_latency = Histogram(
    "function_duration_seconds",
    "Function duration",
    ["function"]
)


def track_metrics(func):
    """Decorador para trackear mÃ©tricas de una funciÃ³n."""
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        request_count.labels(function=func.__name__).inc()
        
        start = time.perf_counter()
        try:
            return await func(*args, **kwargs)
        finally:
            duration = time.perf_counter() - start
            request_latency.labels(function=func.__name__).observe(duration)
    
    return wrapper


# Uso
@track_metrics
async def process_payment(order_id: int) -> Payment:
    # ...
    pass
```

### Instrumentator con MÃ©tricas Custom

```python
from prometheus_fastapi_instrumentator import Instrumentator
from prometheus_fastapi_instrumentator.metrics import Info
from prometheus_client import Counter

# MÃ©trica custom
failed_logins = Counter(
    "failed_login_attempts_total",
    "Failed login attempts",
    ["reason"]
)


def custom_metrics():
    """AÃ±ade mÃ©tricas personalizadas al instrumentator."""
    
    def instrumentation(info: Info):
        # Acceder a request/response
        if info.modified_handler == "/auth/login":
            if info.response.status_code == 401:
                failed_logins.labels(reason="invalid_credentials").inc()
            elif info.response.status_code == 429:
                failed_logins.labels(reason="rate_limited").inc()
    
    return instrumentation


# AÃ±adir al instrumentator
instrumentator.add(custom_metrics())
```

---

## Dashboards y Alertas

### Docker Compose con Prometheus + Grafana

```yaml
# docker-compose.yml
services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - ENABLE_METRICS=true

  prometheus:
    image: prom/prometheus:v2.48.0
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'

  grafana:
    image: grafana/grafana:10.2.0
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  grafana_data:
```

### ConfiguraciÃ³n de Prometheus

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'fastapi'
    static_configs:
      - targets: ['api:8000']
    metrics_path: /metrics
```

### Queries Ãštiles en Prometheus/Grafana

```promql
# Requests por segundo
rate(http_requests_total[5m])

# Requests por segundo por endpoint
rate(http_requests_total{handler="/api/users"}[5m])

# Tasa de errores (%)
sum(rate(http_requests_total{status=~"5.."}[5m])) 
/ 
sum(rate(http_requests_total[5m])) * 100

# Latencia p95
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# Latencia p99 por endpoint
histogram_quantile(0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (handler, le)
)

# Ã“rdenes por minuto
rate(orders_created_total[1m]) * 60
```

### Alertas BÃ¡sicas

```yaml
# prometheus_rules.yml
groups:
  - name: fastapi
    rules:
      # Alerta si tasa de errores > 5%
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) 
          / sum(rate(http_requests_total[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }}"
      
      # Alerta si latencia p95 > 1s
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
          description: "p95 latency is {{ $value }}s"
```

---

## Ejemplo Completo

```python
# src/main.py
from fastapi import FastAPI
from contextlib import asynccontextmanager
from prometheus_fastapi_instrumentator import Instrumentator

from src.metrics import setup_metrics, active_users


@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    setup_metrics(app)
    yield
    # Shutdown


app = FastAPI(lifespan=lifespan)


# src/metrics.py
from prometheus_fastapi_instrumentator import Instrumentator
from prometheus_client import Counter, Histogram, Gauge

# MÃ©tricas de negocio
orders_total = Counter(
    "business_orders_total",
    "Total orders",
    ["status"]
)

order_processing_time = Histogram(
    "business_order_processing_seconds",
    "Order processing time",
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0]
)

active_users = Gauge(
    "business_active_users",
    "Currently active users"
)


def setup_metrics(app: FastAPI):
    Instrumentator(
        excluded_handlers=["/health", "/metrics"]
    ).instrument(app).expose(app, include_in_schema=False)
```

---

## ðŸ“š Resumen

| Concepto | DescripciÃ³n |
|----------|-------------|
| **Prometheus** | Sistema de mÃ©tricas pull-based |
| **Counter** | Valor que solo incrementa |
| **Gauge** | Valor que sube y baja |
| **Histogram** | DistribuciÃ³n en buckets |
| **Instrumentator** | Auto-instrumentaciÃ³n para FastAPI |
| **Grafana** | VisualizaciÃ³n de mÃ©tricas |

---

## ðŸ”— Recursos

- [Prometheus Documentation](https://prometheus.io/docs/)
- [prometheus-fastapi-instrumentator](https://github.com/trallnag/prometheus-fastapi-instrumentator)
- [Grafana FastAPI Dashboards](https://grafana.com/grafana/dashboards/)
- [RED Method](https://www.weave.works/blog/the-red-method-key-metrics-for-microservices-architecture/)

---

*Siguiente: [05 - Health Checks](05-health-checks.md)*
